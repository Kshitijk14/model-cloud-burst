{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist = pd.read_csv('../artifacts/dataset/historical_preprocessed_data.csv')\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Anomaly Detection\n",
    "\n",
    "## 1.1 Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Z-scores for each feature\n",
    "z_scores = df_hist[columns_to_apply].apply(zscore)\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = 3\n",
    "\n",
    "# Flag data points where the absolute Z-score is greater than the threshold\n",
    "anomalies = (z_scores.abs() > threshold)\n",
    "\n",
    "# Create a DataFrame to list anomalies\n",
    "anomalous_data_zscore = df_hist[anomalies.any(axis=1)]\n",
    "\n",
    "# Display the first few rows of detected anomalies\n",
    "anomalous_data_zscore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 LSTM-based Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the time series features for LSTM training\n",
    "time_series_columns = [\n",
    "    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'rain', 'cloud_cover_low', 'cloud_cover_mid', \n",
    "    'et0_fao_evapotranspiration', 'vapour_pressure_deficit', 'wind_speed_10m', 'wind_speed_100m', 'wind_gusts_10m'\n",
    "]\n",
    "\n",
    "# Prepare the data in sequences for LSTM\n",
    "sequence_length = 24  # e.g., a 24-hour window for each sequence\n",
    "data = df_hist[time_series_columns].values\n",
    "\n",
    "# Reshape into sequences (num_sequences, sequence_length, num_features)\n",
    "num_sequences = data.shape[0] // sequence_length\n",
    "X = data[:num_sequences * sequence_length].reshape(num_sequences, sequence_length, len(time_series_columns))\n",
    "\n",
    "# Define the LSTM autoencoder model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
    "    LSTM(32, activation='relu', return_sequences=False),\n",
    "    RepeatVector(X.shape[1]),\n",
    "    LSTM(32, activation='relu', return_sequences=True),\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    TimeDistributed(Dense(X.shape[2]))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model on normal data (use only normal data if you know it beforehand)\n",
    "history = model.fit(X, X, epochs=50, batch_size=32, validation_split=0.1, shuffle=True)\n",
    "\n",
    "# Compute reconstruction errors\n",
    "X_pred = model.predict(X)\n",
    "mse = np.mean(np.power(X - X_pred, 2), axis=(1, 2))\n",
    "\n",
    "# Set an anomaly threshold (e.g., based on 99th percentile of MSEs)\n",
    "threshold = np.percentile(mse, 99)\n",
    "\n",
    "# Flag sequences as anomalies if the MSE is above the threshold\n",
    "anomalies = mse > threshold\n",
    "\n",
    "# Print a few examples of detected anomalies\n",
    "anomalous_sequences = X[anomalies]\n",
    "print(\"Number of anomalies detected:\", np.sum(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAutoencoderAnomalyDetector:\n",
    "    def __init__(self, sequence_length=24, lstm_units=[64, 32], epochs=50, batch_size=32, threshold_percentile=99):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm_units = lstm_units\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.threshold_percentile = threshold_percentile\n",
    "        self.model = None\n",
    "        # self.scaler = MinMaxScaler()\n",
    "        self.threshold = None\n",
    "\n",
    "    def preprocess_data(self, df, time_series_columns):\n",
    "        # Scale data\n",
    "        # data = self.scaler.fit_transform(df[time_series_columns])\n",
    "        data = df[time_series_columns].values\n",
    "        \n",
    "        # Reshape into sequences\n",
    "        num_sequences = data.shape[0] // self.sequence_length\n",
    "        X = data[:num_sequences * self.sequence_length].reshape(num_sequences, self.sequence_length, len(time_series_columns))\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        # Build LSTM Autoencoder\n",
    "        model = Sequential([\n",
    "            LSTM(self.lstm_units[0], activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "            LSTM(self.lstm_units[1], activation='relu', return_sequences=False),\n",
    "            RepeatVector(input_shape[0]),\n",
    "            \n",
    "            LSTM(self.lstm_units[1], activation='relu', return_sequences=True),\n",
    "            LSTM(self.lstm_units[0], activation='relu', return_sequences=True),\n",
    "            TimeDistributed(Dense(input_shape[1]))\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        self.model = model\n",
    "\n",
    "    def train(self, X):\n",
    "        # Train the autoencoder model\n",
    "        history = self.model.fit(X, X, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.1, shuffle=True)\n",
    "        return history\n",
    "\n",
    "    def compute_reconstruction_error(self, X):\n",
    "        # Predict and calculate reconstruction error\n",
    "        X_pred = self.model.predict(X)\n",
    "        mse = np.mean(np.power(X - X_pred, 2), axis=(1, 2))\n",
    "        return mse\n",
    "\n",
    "    def set_threshold(self, mse):\n",
    "        # Set anomaly threshold based on the specified percentile\n",
    "        self.threshold = np.percentile(mse, self.threshold_percentile)\n",
    "        \n",
    "    def detect_anomalies(self, mse):\n",
    "        # Detect anomalies based on reconstruction error and threshold\n",
    "        return mse > self.threshold\n",
    "\n",
    "    def fit_predict(self, df, time_series_columns):\n",
    "        # Full pipeline from preprocessing, training, and detecting anomalies\n",
    "        X = self.preprocess_data(df, time_series_columns)\n",
    "        input_shape = (X.shape[1], X.shape[2])\n",
    "        \n",
    "        # Build, train model and compute reconstruction error\n",
    "        self.build_model(input_shape)\n",
    "        self.train(X)\n",
    "        mse = self.compute_reconstruction_error(X)\n",
    "        \n",
    "        # Set threshold and detect anomalies\n",
    "        self.set_threshold(mse)\n",
    "        anomalies = self.detect_anomalies(mse)\n",
    "        \n",
    "        return X[anomalies], np.sum(anomalies)  # Return anomalous sequences and count\n",
    "\n",
    "# Define columns to be used\n",
    "time_series_columns = [\n",
    "    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'rain', 'cloud_cover_low', \n",
    "    'cloud_cover_mid', 'et0_fao_evapotranspiration', 'vapour_pressure_deficit', \n",
    "    'wind_speed_10m', 'wind_speed_100m', 'wind_gusts_10m'\n",
    "]\n",
    "\n",
    "# Instantiate the anomaly detector class\n",
    "anomaly_detector = LSTMAutoencoderAnomalyDetector(sequence_length=24, epochs=50, batch_size=32)\n",
    "\n",
    "# Detect anomalies in data\n",
    "anomalous_sequences, num_anomalies = anomaly_detector.fit_predict(df_hist, time_series_columns)\n",
    "print(\"Number of anomalies detected:\", num_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for events like Cloudbursts (CB) & Mini-Cloudbursts (MCB) based on periods with rainfall intensities.\n",
    "\n",
    "1. **Heavy Rainfall**: Rainfall > *6.5 cm/day*\n",
    "2. **Very Heavy Rainfall**: Rainfall > *13.0 cm/day*\n",
    "3. **Extremely Heavy Rainfall**: Rainfall > *20.0 cm/day*\n",
    "3. **Cloudburst (CB)**: Rainfall > *10 cm in a single hour*\n",
    "4. **Mini-Cloud Burst (MCB)**: Rainfall exceeds *5 cm over any two consecutive hours*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
