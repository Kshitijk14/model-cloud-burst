{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Fetched Data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched Data: {'DHT_11': {'Humidity': 72, 'Temperature': 26.1}, 'Precipitation': {'Rain': 4095}}\n",
      "Data has been saved and updated in 'fetched_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the URL and parameters\n",
    "url = \"https://cloudburst-993f5-default-rtdb.firebaseio.com/.json\"\n",
    "params = {\n",
    "    \"auth\": \"{FIREBASE_API_KEY}\"\n",
    "}\n",
    "\n",
    "# Fetch data\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Fetched Data:\", data)\n",
    "    \n",
    "    # Extract relevant information and flatten the structure\n",
    "    humidity = data['DHT_11']['Humidity']\n",
    "    temperature = data['DHT_11']['Temperature']\n",
    "    rain = data['Precipitation']['Rain']\n",
    "    \n",
    "    # Create a DataFrame with the extracted data\n",
    "    new_data_df = pd.DataFrame({\n",
    "        'Humidity': [humidity],\n",
    "        'Temperature': [temperature],\n",
    "        'Rain': [rain]\n",
    "    })\n",
    "\n",
    "    # Define CSV file path\n",
    "    csv_file = \"../artifacts/dataset/fetched_hardware_data.csv\"\n",
    "    \n",
    "    # Check if the CSV file exists\n",
    "    if os.path.exists(csv_file):\n",
    "        # Load existing data\n",
    "        existing_data_df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Append new data to existing data\n",
    "        updated_data_df = pd.concat([existing_data_df, new_data_df], ignore_index=True)\n",
    "    else:\n",
    "        # If the file doesn't exist, use only the new data\n",
    "        updated_data_df = new_data_df\n",
    "\n",
    "    # Save updated data back to CSV\n",
    "    updated_data_df.to_csv(csv_file, index=False)\n",
    "    print(\"Data has been saved and updated in 'fetched_data.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web-browser Script\n",
    "\n",
    "ref: https://www.geeksforgeeks.org/schedule-a-python-script-to-run-daily/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import webbrowser\n",
    "\n",
    "# Define the URL and parameters\n",
    "firebase_url = \"https://cloudburst-993f5-default-rtdb.firebaseio.com/.json\"\n",
    "params = {\n",
    "    \"auth\": \"{FIREBASE_API_KEY}\"\n",
    "}\n",
    "\n",
    "# Fetch data\n",
    "response = requests.get(firebase_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Fetched Data:\", data)\n",
    "    \n",
    "    # Convert the data to a DataFrame\n",
    "    new_data_df = pd.DataFrame([data])  # Adjust based on the structure of `data`\n",
    "\n",
    "    # Define CSV file path\n",
    "    csv_file = \"fetched_data.csv\"\n",
    "    \n",
    "    # Check if the CSV file exists\n",
    "    if os.path.exists(csv_file):\n",
    "        # Load existing data\n",
    "        existing_data_df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Append new data to existing data\n",
    "        updated_data_df = pd.concat([existing_data_df, new_data_df], ignore_index=True)\n",
    "    else:\n",
    "        # If the file doesn't exist, use only the new data\n",
    "        updated_data_df = new_data_df\n",
    "\n",
    "    # Save updated data back to CSV\n",
    "    updated_data_df.to_csv(csv_file, index=False)\n",
    "    print(\"Data has been saved and updated in 'fetched_data.csv'\")\n",
    "\n",
    "    # Open the CSV file URL in the browser (assumes you upload to Google Drive or a similar service)\n",
    "    # Here, we're demonstrating opening a link; replace with an actual link if needed\n",
    "    drive_url = \"https://docs.google.com/spreadsheets/u/0/\"\n",
    "    chrome_path = r'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'\n",
    "\n",
    "    # Register and open in Chrome\n",
    "    webbrowser.register('chrome', None, webbrowser.BackgroundBrowser(chrome_path))\n",
    "    webbrowser.get('chrome').open_new_tab(drive_url)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
